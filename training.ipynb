{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T03:54:20.246950Z","iopub.status.busy":"2024-04-29T03:54:20.246598Z","iopub.status.idle":"2024-04-29T03:54:20.254940Z","shell.execute_reply":"2024-04-29T03:54:20.254073Z","shell.execute_reply.started":"2024-04-29T03:54:20.246921Z"},"trusted":true},"outputs":[],"source":["import json\n","\n","import re\n","import unicodedata\n","import codecs\n","\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","import torch.nn.functional as F\n","\n","import itertools\n","\n","import json"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T03:57:08.196220Z","iopub.status.busy":"2024-04-29T03:57:08.195379Z","iopub.status.idle":"2024-04-29T03:57:08.204771Z","shell.execute_reply":"2024-04-29T03:57:08.203749Z","shell.execute_reply.started":"2024-04-29T03:57:08.196165Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'2.1.2'"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["torch.__version__"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T04:03:51.438565Z","iopub.status.busy":"2024-04-29T04:03:51.437852Z","iopub.status.idle":"2024-04-29T04:03:51.442917Z","shell.execute_reply":"2024-04-29T04:03:51.441989Z","shell.execute_reply.started":"2024-04-29T04:03:51.438532Z"},"trusted":true},"outputs":[],"source":["USE_CUDA = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T04:03:51.945230Z","iopub.status.busy":"2024-04-29T04:03:51.944843Z","iopub.status.idle":"2024-04-29T04:03:51.950415Z","shell.execute_reply":"2024-04-29T04:03:51.949549Z","shell.execute_reply.started":"2024-04-29T04:03:51.945194Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["print(device)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-28T21:46:09.006724Z","iopub.status.busy":"2024-04-28T21:46:09.006379Z","iopub.status.idle":"2024-04-28T21:46:10.720660Z","shell.execute_reply":"2024-04-28T21:46:10.719561Z","shell.execute_reply.started":"2024-04-28T21:46:09.006700Z"},"trusted":true},"outputs":[],"source":["datasets = [\"/cardano.stackexchange.com_title_best_upvoted_answer.jsonl\",\\\n","           \"/bitcoin.stackexchange.com_title_best_upvoted_answer.jsonl\",\\\n","           \"/crypto.stackexchange.com_title_best_upvoted_answer.jsonl\",\\\n","           \"/ethereum.stackexchange.com_title_best_upvoted_answer.jsonl\"]\n","\n","def get_example(line):\n","    return [line[0], line[1]]\n","\n","qna_data = []\n","for filepath in datasets:\n","    with open(filepath, 'rt') as file:\n","            for line in file:\n","                example = get_example(json.loads(line))\n","                if example is not None:\n","                    qna_data.append(example)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T04:27:12.657538Z","iopub.status.busy":"2024-04-29T04:27:12.657159Z","iopub.status.idle":"2024-04-29T04:27:12.663332Z","shell.execute_reply":"2024-04-29T04:27:12.662251Z","shell.execute_reply.started":"2024-04-29T04:27:12.657510Z"},"trusted":true},"outputs":[{"data":{"text/plain":["68250"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["len(qna_data)"]},{"cell_type":"markdown","metadata":{},"source":["## Load and Preprocess Data"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T04:27:16.717776Z","iopub.status.busy":"2024-04-29T04:27:16.717434Z","iopub.status.idle":"2024-04-29T04:27:16.728780Z","shell.execute_reply":"2024-04-29T04:27:16.727802Z","shell.execute_reply.started":"2024-04-29T04:27:16.717751Z"},"trusted":true},"outputs":[],"source":["# Creating a Vocabulary object \n","PAD_token = 0\n","SOS_token = 1\n","EOS_token = 2\n","\n","class Voc:\n","    def __init__(self):\n","        self.trimmed = False\n","        self.word2index = {}\n","        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n","        self.word2count = {}\n","        self.num_words = 3 \n","        \n","    def addSentence(self, sentence):\n","        for word in sentence.split(\" \"):\n","            self.addWord(word)\n","            \n","    def addWord(self, word):\n","        if word not in self.word2index:\n","            self.word2index[word] = self.num_words\n","            self.word2count[word] = 1\n","            self.index2word[self.num_words] = word\n","            self.num_words += 1\n","        else:\n","            self.word2count[word] += 1\n","            \n","    def trim(self, min_count):\n","        if self.trimmed:\n","            return\n","        self.trimmed = True\n","\n","        keep_words = []\n","\n","        for k, v in self.word2count.items():\n","            if v >= min_count:\n","                keep_words.append(k)\n","\n","        print('keep_words {} / {} = {:.4f}'.format(\n","            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n","        ))\n","\n","        # Reinitialize dictionaries\n","        self.word2index = {}\n","        self.word2count = {}\n","        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n","        self.num_words = 3 # Count default tokens\n","\n","        for word in keep_words:\n","            self.addWord(word)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T04:27:21.558435Z","iopub.status.busy":"2024-04-29T04:27:21.558064Z","iopub.status.idle":"2024-04-29T04:28:19.577873Z","shell.execute_reply":"2024-04-29T04:28:19.576891Z","shell.execute_reply.started":"2024-04-29T04:27:21.558408Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Start preparing training data ...\n","Read 68250 sentence pairs\n","Trimmed to 4802 sentence pairs\n","Counting words...\n","Counted words: 9298\n"]}],"source":["MAX_LENGTH = 30\n","\n","def unicodeToAscii(s):\n","    return ''.join(\n","        c for c in unicodedata.normalize('NFD', s)\n","        if unicodedata.category(c) != 'Mn'\n","    )\n","\n","def normalizeString(s):\n","    s = unicodeToAscii(s.lower().strip())\n","    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n","    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n","    s = re.sub(r\"(https?:\\/\\/)?([\\da-z\\.-]+)\\.([a-z\\.]{2,6})([\\/\\w\\.-]*)\", r\" \", s)\n","    s = re.sub(r\"\\s+\", r\" \", s).strip()\n","    return s\n","\n","def filterPair(p):\n","    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH\n","\n","def filterPairs(pairs):\n","    return [pair for pair in pairs if filterPair(pair)]\n","\n","def readVocs(data):\n","    pairs = [[normalizeString(s) for s in pair] for pair in data]\n","    voc = Voc()\n","    return voc, pairs\n","    \n","\n","def loadPrepareData(data):\n","    print(\"Start preparing training data ...\")\n","    voc, pairs = readVocs(data)\n","    print(\"Read {!s} sentence pairs\".format(len(pairs)))\n","    pairs = filterPairs(pairs)\n","    print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))\n","    print(\"Counting words...\")\n","    for pair in pairs:\n","        voc.addSentence(pair[0])\n","        voc.addSentence(pair[1])\n","    print(\"Counted words:\", voc.num_words)\n","    return voc, pairs\n","\n","voc, pairs = loadPrepareData(qna_data)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T04:31:00.914659Z","iopub.status.busy":"2024-04-29T04:31:00.913766Z","iopub.status.idle":"2024-04-29T04:31:00.958046Z","shell.execute_reply":"2024-04-29T04:31:00.957227Z","shell.execute_reply.started":"2024-04-29T04:31:00.914625Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["keep_words 4960 / 9295 = 0.5336\n","Trimmed from 4802 pairs to 2308, 0.4806 of total\n"]}],"source":["# TRIM rare words\n","MIN_COUNT = 2    # Minimum word count threshold for trimming\n","\n","def trimRareWords(voc, pairs, MIN_COUNT):\n","    # Trim words used under the MIN_COUNT from the voc\n","    voc.trim(MIN_COUNT)\n","    # Filter out pairs with trimmed words\n","    keep_pairs = []\n","    for pair in pairs:\n","        input_sentence = pair[0]\n","        output_sentence = pair[1]\n","        keep_input = True\n","        keep_output = True\n","        # Check input sentence\n","        for word in input_sentence.split(' '):\n","            if word not in voc.word2index:\n","                keep_input = False\n","                break\n","        # Check output sentence\n","        for word in output_sentence.split(' '):\n","            if word not in voc.word2index:\n","                keep_output = False\n","                break\n","\n","        # Only keep pairs that do not contain trimmed word(s) in their input or output sentence\n","        if keep_input and keep_output:\n","            keep_pairs.append(pair)\n","\n","    print(\"Trimmed from {} pairs to {}, {:.4f} of total\".format(len(pairs), len(keep_pairs), len(keep_pairs) / len(pairs)))\n","    return keep_pairs\n","\n","\n","# Trim voc and pairs\n","pairs = trimRareWords(voc, pairs, MIN_COUNT)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Prepare Data for Model"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T04:31:38.732378Z","iopub.status.busy":"2024-04-29T04:31:38.731698Z","iopub.status.idle":"2024-04-29T04:31:38.744274Z","shell.execute_reply":"2024-04-29T04:31:38.743392Z","shell.execute_reply.started":"2024-04-29T04:31:38.732347Z"},"trusted":true},"outputs":[],"source":["def indexesFromSentence(voc, sentence):\n","    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n","\n","def zeroPadding(l, fillvalue=PAD_token):\n","    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n","\n","def binaryMatrix(l, value=PAD_token):\n","    m = []\n","    for i, seq in enumerate(l):\n","        m.append([])\n","        for token in seq:\n","            if token == PAD_token:\n","                m[i].append(0)\n","            else:\n","                m[i].append(1)\n","    return m\n","\n","# Returns padded input sequence tensor and lengths\n","def inputVar(l, voc):\n","    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n","    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n","    padList = zeroPadding(indexes_batch)\n","    padVar = torch.LongTensor(padList)\n","    return padVar, lengths\n","\n","# Returns padded target sequence tensor, padding mask, and max target length\n","def outputVar(l, voc):\n","    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n","    max_target_len = max([len(indexes) for indexes in indexes_batch])\n","    padList = zeroPadding(indexes_batch)\n","    mask = binaryMatrix(padList)\n","    mask = torch.BoolTensor(mask)\n","    padVar = torch.LongTensor(padList)\n","    return padVar, mask, max_target_len\n","\n","# Returns all items for a given batch of pairs\n","def batch2TrainData(voc, pair_batch):\n","    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n","    input_batch, output_batch = [], []\n","    for pair in pair_batch:\n","        input_batch.append(pair[0])\n","        output_batch.append(pair[1])\n","    inp, lengths = inputVar(input_batch, voc)\n","    output, mask, max_target_len = outputVar(output_batch, voc)\n","    return inp, lengths, output, mask, max_target_len"]},{"cell_type":"markdown","metadata":{},"source":["## Defining Models"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T04:31:39.619629Z","iopub.status.busy":"2024-04-29T04:31:39.618857Z","iopub.status.idle":"2024-04-29T04:31:39.627591Z","shell.execute_reply":"2024-04-29T04:31:39.626586Z","shell.execute_reply.started":"2024-04-29T04:31:39.619595Z"},"trusted":true},"outputs":[],"source":["class EncoderRNN(nn.Module):\n","    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n","        super(EncoderRNN, self).__init__()\n","        self.n_layers = n_layers\n","        self.hidden_size = hidden_size\n","        self.embedding = embedding\n","\n","        # Initialize GRU; the input_size and hidden_size parameters are both set to 'hidden_size'\n","        #   because our input size is a word embedding with number of features == hidden_size\n","        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,\n","                          dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n","\n","    def forward(self, input_seq, input_lengths, hidden=None):\n","        # Convert word indexes to embeddings\n","        embedded = self.embedding(input_seq)\n","        # Pack padded batch of sequences for RNN module\n","        packed = nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n","        # Forward pass through GRU\n","        outputs, hidden = self.gru(packed, hidden)\n","        # Unpack padding\n","        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs)\n","        # Sum bidirectional GRU outputs\n","        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n","        # Return output and final hidden state\n","        return outputs, hidden"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T04:31:40.165156Z","iopub.status.busy":"2024-04-29T04:31:40.164784Z","iopub.status.idle":"2024-04-29T04:31:40.176530Z","shell.execute_reply":"2024-04-29T04:31:40.175658Z","shell.execute_reply.started":"2024-04-29T04:31:40.165127Z"},"trusted":true},"outputs":[],"source":["# Luong attention layer\n","class Attn(nn.Module):\n","    def __init__(self, method, hidden_size):\n","        super(Attn, self).__init__()\n","        self.method = method\n","        if self.method not in ['dot', 'general', 'concat']:\n","            raise ValueError(self.method, \"is not an appropriate attention method.\")\n","        self.hidden_size = hidden_size\n","        if self.method == 'general':\n","            self.attn = nn.Linear(self.hidden_size, hidden_size)\n","        elif self.method == 'concat':\n","            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n","            self.v = nn.Parameter(torch.FloatTensor(hidden_size))\n","\n","    def dot_score(self, hidden, encoder_output):\n","        return torch.sum(hidden * encoder_output, dim=2)\n","\n","    def general_score(self, hidden, encoder_output):\n","        energy = self.attn(encoder_output)\n","        return torch.sum(hidden * energy, dim=2)\n","\n","    def concat_score(self, hidden, encoder_output):\n","        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n","        return torch.sum(self.v * energy, dim=2)\n","\n","    def forward(self, hidden, encoder_outputs):\n","        # Calculate the attention weights (energies) based on the given method\n","        if self.method == 'general':\n","            attn_energies = self.general_score(hidden, encoder_outputs)\n","        elif self.method == 'concat':\n","            attn_energies = self.concat_score(hidden, encoder_outputs)\n","        elif self.method == 'dot':\n","            attn_energies = self.dot_score(hidden, encoder_outputs)\n","\n","        # Transpose max_length and batch_size dimensions\n","        attn_energies = attn_energies.t()\n","\n","        # Return the softmax normalized probability scores (with added dimension)\n","        return F.softmax(attn_energies, dim=1).unsqueeze(1)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T04:31:40.711702Z","iopub.status.busy":"2024-04-29T04:31:40.710882Z","iopub.status.idle":"2024-04-29T04:31:40.722372Z","shell.execute_reply":"2024-04-29T04:31:40.721489Z","shell.execute_reply.started":"2024-04-29T04:31:40.711670Z"},"trusted":true},"outputs":[],"source":["class LuongAttnDecoderRNN(nn.Module):\n","    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n","        super(LuongAttnDecoderRNN, self).__init__()\n","\n","        # Keep for reference\n","        self.attn_model = attn_model\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.n_layers = n_layers\n","        self.dropout = dropout\n","\n","        # Define layers\n","        self.embedding = embedding\n","        self.embedding_dropout = nn.Dropout(dropout)\n","        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n","        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n","        self.out = nn.Linear(hidden_size, output_size)\n","\n","        self.attn = Attn(attn_model, hidden_size)\n","\n","    def forward(self, input_step, last_hidden, encoder_outputs):\n","        # Note: we run this one step (word) at a time\n","        # Get embedding of current input word\n","        embedded = self.embedding(input_step)\n","        embedded = self.embedding_dropout(embedded)\n","        # Forward through unidirectional GRU\n","        rnn_output, hidden = self.gru(embedded, last_hidden)\n","        # Calculate attention weights from the current GRU output\n","        attn_weights = self.attn(rnn_output, encoder_outputs)\n","        # Multiply attention weights to encoder outputs to get new \"weighted sum\" context vector\n","        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n","        # Concatenate weighted context vector and GRU output using Luong eq. 5\n","        rnn_output = rnn_output.squeeze(0)\n","        context = context.squeeze(1)\n","        concat_input = torch.cat((rnn_output, context), 1)\n","        concat_output = torch.tanh(self.concat(concat_input))\n","        # Predict next word using Luong eq. 6\n","        output = self.out(concat_output)\n","        output = F.softmax(output, dim=1)\n","        # Return output and final hidden state\n","        return output, hidden"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T04:31:41.170743Z","iopub.status.busy":"2024-04-29T04:31:41.170060Z","iopub.status.idle":"2024-04-29T04:31:41.176072Z","shell.execute_reply":"2024-04-29T04:31:41.175086Z","shell.execute_reply.started":"2024-04-29T04:31:41.170708Z"},"trusted":true},"outputs":[],"source":["def maskNLLLoss(inp, target, mask):\n","    nTotal = mask.sum()\n","    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n","    loss = crossEntropy.masked_select(mask).mean()\n","    loss = loss.to(device)\n","    return loss, nTotal.item()"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T04:31:41.609644Z","iopub.status.busy":"2024-04-29T04:31:41.608971Z","iopub.status.idle":"2024-04-29T04:31:41.622745Z","shell.execute_reply":"2024-04-29T04:31:41.621778Z","shell.execute_reply.started":"2024-04-29T04:31:41.609604Z"},"trusted":true},"outputs":[],"source":["def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding,\n","          encoder_optimizer, decoder_optimizer, batch_size, clip, max_length=MAX_LENGTH):\n","\n","    # Zero gradients\n","    encoder_optimizer.zero_grad()\n","    decoder_optimizer.zero_grad()\n","\n","    # Set device options\n","    input_variable = input_variable.to(device)\n","    target_variable = target_variable.to(device)\n","    mask = mask.to(device)\n","    # Lengths for RNN packing should always be on the CPU\n","    lengths = lengths.to(\"cpu\")\n","\n","    # Initialize variables\n","    loss = 0\n","    print_losses = []\n","    n_totals = 0\n","\n","    # Forward pass through encoder\n","    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n","\n","    # Create initial decoder input (start with SOS tokens for each sentence)\n","    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n","    decoder_input = decoder_input.to(device)\n","\n","    # Set initial decoder hidden state to the encoder's final hidden state\n","    decoder_hidden = encoder_hidden[:decoder.n_layers]\n","\n","    # Determine if we are using teacher forcing this iteration\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n","\n","    # Forward batch of sequences through decoder one time step at a time\n","    if use_teacher_forcing:\n","        for t in range(max_target_len):\n","            decoder_output, decoder_hidden = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs\n","            )\n","            # Teacher forcing: next input is current target\n","            decoder_input = target_variable[t].view(1, -1)\n","            # Calculate and accumulate loss\n","            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n","            loss += mask_loss\n","            print_losses.append(mask_loss.item() * nTotal)\n","            n_totals += nTotal\n","    else:\n","        for t in range(max_target_len):\n","            decoder_output, decoder_hidden = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs\n","            )\n","            # No teacher forcing: next input is decoder's own current output\n","            _, topi = decoder_output.topk(1)\n","            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n","            decoder_input = decoder_input.to(device)\n","            # Calculate and accumulate loss\n","            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n","            loss += mask_loss\n","            print_losses.append(mask_loss.item() * nTotal)\n","            n_totals += nTotal\n","\n","    # Perform backpropagation\n","    loss.backward()\n","\n","    # Clip gradients: gradients are modified in place\n","    _ = nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n","    _ = nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n","\n","    # Adjust model weights\n","    encoder_optimizer.step()\n","    decoder_optimizer.step()\n","\n","    return sum(print_losses) / n_totals"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T06:30:17.880450Z","iopub.status.busy":"2024-04-29T06:30:17.879644Z","iopub.status.idle":"2024-04-29T06:30:17.891385Z","shell.execute_reply":"2024-04-29T06:30:17.890468Z","shell.execute_reply.started":"2024-04-29T06:30:17.880420Z"},"trusted":true},"outputs":[],"source":["def trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, loadFilename):\n","\n","    # Load batches for each iteration\n","    training_batches = []\n","    for _ in range(100):\n","        random.shuffle(pairs)\n","        training_batch = [batch2TrainData(voc, pairs[_: _ + batch_size])\n","                      for _ in range(0, len(pairs), batch_size)]\n","        training_batches.extend(training_batch)\n","\n","    # Initializations\n","    print('Initializing ...')\n","    start_iteration = 1\n","    print_loss = 0\n","    if loadFilename:\n","        start_iteration = checkpoint['iteration'] + 1\n","\n","    # Training loop\n","    print(\"Training...\")\n","    for iteration in range(start_iteration, n_iteration + 1):\n","        training_batch = training_batches[iteration - 1]\n","        # Extract fields from batch\n","        input_variable, lengths, target_variable, mask, max_target_len = training_batch\n","\n","        # Run a training iteration with batch\n","        loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n","                     decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip)\n","        print_loss += loss\n","\n","        # Print progress\n","        if iteration % print_every == 0:\n","            print_loss_avg = print_loss / print_every\n","            print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n","            print_loss = 0\n","\n","        # Save checkpoint\n","        if (iteration % save_every == 0):\n","#             directory = os.path.join(save_dir, model_name,'{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size))\n","#             if not os.path.exists(directory):\n","#                 os.makedirs(directory)\n","            torch.save({\n","                'iteration': iteration,\n","                'en': encoder.state_dict(),\n","                'de': decoder.state_dict(),\n","                'en_opt': encoder_optimizer.state_dict(),\n","                'de_opt': decoder_optimizer.state_dict(),\n","                'loss': loss,\n","                'voc_dict': voc.__dict__,\n","                'embedding': embedding.state_dict()\n","            }, \"cryptoBot_checkpoint.pth\")"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T04:36:35.818087Z","iopub.status.busy":"2024-04-29T04:36:35.817256Z","iopub.status.idle":"2024-04-29T04:36:35.826901Z","shell.execute_reply":"2024-04-29T04:36:35.825944Z","shell.execute_reply.started":"2024-04-29T04:36:35.818057Z"},"trusted":true},"outputs":[],"source":["class GreedySearchDecoder(nn.Module):\n","    def __init__(self, encoder, decoder):\n","        super(GreedySearchDecoder, self).__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","\n","    def forward(self, input_seq, input_length, max_length):\n","        # Forward input through encoder model\n","        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n","        # Prepare encoder's final hidden layer to be first hidden input to the decoder\n","        decoder_hidden = encoder_hidden[:decoder.n_layers]\n","        # Initialize decoder input with SOS_token\n","        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_token\n","        # Initialize tensors to append decoded words to\n","        all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n","        all_scores = torch.zeros([0], device=device)\n","        # Iteratively decode one word token at a time\n","        for _ in range(max_length):\n","            # Forward pass through decoder\n","            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n","            # Obtain most likely word token and its softmax score\n","            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n","            # Record token and score\n","            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n","            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n","            # Prepare current token to be next decoder input (add a dimension)\n","            decoder_input = torch.unsqueeze(decoder_input, 0)\n","        # Return collections of word tokens and scores\n","        return all_tokens, all_scores"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T04:36:38.983071Z","iopub.status.busy":"2024-04-29T04:36:38.982410Z","iopub.status.idle":"2024-04-29T04:36:38.992620Z","shell.execute_reply":"2024-04-29T04:36:38.991654Z","shell.execute_reply.started":"2024-04-29T04:36:38.983044Z"},"trusted":true},"outputs":[],"source":["def evaluate(encoder, decoder, searcher, voc, sentence, max_length=MAX_LENGTH):\n","    ### Format input sentence as a batch\n","    # words -> indexes\n","    indexes_batch = [indexesFromSentence(voc, sentence)]\n","    # Create lengths tensor\n","    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n","    # Transpose dimensions of batch to match models' expectations\n","    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n","    # Use appropriate device\n","    input_batch = input_batch.to(device)\n","    lengths = lengths.to(\"cpu\")\n","    # Decode sentence with searcher\n","    tokens, scores = searcher(input_batch, lengths, max_length)\n","    # indexes -> words\n","    decoded_words = [voc.index2word[token.item()] for token in tokens]\n","    return decoded_words\n","\n","\n","def evaluateInput(encoder, decoder, searcher, voc):\n","    input_sentence = ''\n","    while(1):\n","        try:\n","            # Get input sentence\n","            input_sentence = input('> ')\n","            # Check if it is quit case\n","            if input_sentence == 'q' or input_sentence == 'quit': break\n","            # Normalize sentence\n","            input_sentence = normalizeString(input_sentence)\n","            # Evaluate sentence\n","            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n","            # Format and print response sentence\n","            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n","            print('Bot:', ' '.join(output_words))\n","\n","        except KeyError:\n","            print(\"Error: Encountered unknown word.\")"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T04:39:43.131428Z","iopub.status.busy":"2024-04-29T04:39:43.131078Z","iopub.status.idle":"2024-04-29T04:39:43.136349Z","shell.execute_reply":"2024-04-29T04:39:43.135315Z","shell.execute_reply.started":"2024-04-29T04:39:43.131403Z"},"trusted":true},"outputs":[],"source":["# Configure models\n","model_name = 'cryptoBot_model'\n","attn_model = 'dot'\n","#``attn_model = 'general'``\n","#``attn_model = 'concat'``\n","hidden_size = 500\n","encoder_n_layers = 4\n","decoder_n_layers = 4\n","dropout = 0.1\n","batch_size = 4\n","\n","# Set checkpoint to load from; set to None if starting from scratch\n","loadFilename = None\n","checkpoint_iter = None"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T04:39:49.219529Z","iopub.status.busy":"2024-04-29T04:39:49.219193Z","iopub.status.idle":"2024-04-29T04:39:49.596739Z","shell.execute_reply":"2024-04-29T04:39:49.595812Z","shell.execute_reply.started":"2024-04-29T04:39:49.219505Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Building encoder and decoder ...\n","Models built and ready to go!\n"]}],"source":["if loadFilename:\n","    # If loading on same machine the model was trained on\n","    checkpoint = torch.load(loadFilename)\n","    # If loading a model trained on GPU to CPU\n","    #checkpoint = torch.load(loadFilename, map_location=torch.device('cpu'))\n","    encoder_sd = checkpoint['en']\n","    decoder_sd = checkpoint['de']\n","    encoder_optimizer_sd = checkpoint['en_opt']\n","    decoder_optimizer_sd = checkpoint['de_opt']\n","    embedding_sd = checkpoint['embedding']\n","    voc.__dict__ = checkpoint['voc_dict']\n","\n","\n","print('Building encoder and decoder ...')\n","# Initialize word embeddings\n","embedding = nn.Embedding(voc.num_words, hidden_size)\n","if loadFilename:\n","    embedding.load_state_dict(embedding_sd)\n","# Initialize encoder & decoder models\n","encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n","decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n","if loadFilename:\n","    encoder.load_state_dict(encoder_sd)\n","    decoder.load_state_dict(decoder_sd)\n","# Use appropriate device\n","encoder = encoder.to(device)\n","decoder = decoder.to(device)\n","print('Models built and ready to go!')"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T04:39:55.494728Z","iopub.status.busy":"2024-04-29T04:39:55.493924Z","iopub.status.idle":"2024-04-29T04:40:16.659662Z","shell.execute_reply":"2024-04-29T04:40:16.658673Z","shell.execute_reply.started":"2024-04-29T04:39:55.494690Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":[">  who created bitcoin\n"]},{"name":"stdout","output_type":"stream","text":["Bot: stamp stamp stamp listen listen listen callcontract callcontract callcontract listen listen listen callcontract callcontract callcontract listen listen listen importaddress callcontract callcontract callcontract listen listen listen callcontract callcontract callcontract listen listen\n"]},{"name":"stdout","output_type":"stream","text":[">  cardano private wallet\n"]},{"name":"stdout","output_type":"stream","text":["Bot: ensure ensure executing helps helps referred referred referred stands stands stands stands stands deterministic deterministic deterministic deterministic deterministic deterministic deterministic deterministic deterministic promises promises listeners listeners listeners listeners helps helps\n"]},{"name":"stdout","output_type":"stream","text":[">  exit\n"]},{"name":"stdout","output_type":"stream","text":["Bot: linux helps helps helps helps helps stands stands stands gavcoins gavcoins gavcoins gavcoins sqlite sqlite sqlite sqlite sqlite sqlite sqlite sqlite sqlite sqlite sqlite sqlite sqlite sqlite sqlite sqlite sqlite\n"]},{"name":"stdout","output_type":"stream","text":[">  quit\n"]}],"source":["# Set dropout layers to ``eval`` mode\n","encoder.eval()\n","decoder.eval()\n","\n","# Initialize search module\n","searcher = GreedySearchDecoder(encoder, decoder)\n","\n","# Begin chatting (uncomment and run the following line to begin)\n","evaluateInput(encoder, decoder, searcher, voc)"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T07:52:32.449477Z","iopub.status.busy":"2024-04-29T07:52:32.448910Z","iopub.status.idle":"2024-04-29T09:05:34.812102Z","shell.execute_reply":"2024-04-29T09:05:34.811118Z","shell.execute_reply.started":"2024-04-29T07:52:32.449440Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Building optimizers ...\n","Starting Training!\n","Initializing ...\n","Training...\n","Iteration: 5770; Percent complete: 10.0%; Average loss: 0.0651\n","Iteration: 11540; Percent complete: 20.0%; Average loss: 0.0653\n","Iteration: 17310; Percent complete: 30.0%; Average loss: 0.0634\n","Iteration: 23080; Percent complete: 40.0%; Average loss: 0.0637\n","Iteration: 28850; Percent complete: 50.0%; Average loss: 0.0616\n","Iteration: 34620; Percent complete: 60.0%; Average loss: 0.0622\n","Iteration: 40390; Percent complete: 70.0%; Average loss: 0.0603\n","Iteration: 46160; Percent complete: 80.0%; Average loss: 0.0602\n","Iteration: 51930; Percent complete: 90.0%; Average loss: 0.0598\n","Iteration: 57700; Percent complete: 100.0%; Average loss: 0.0594\n"]}],"source":["# Configure training/optimization\n","clip = 50.0\n","teacher_forcing_ratio = 1.0\n","learning_rate = 0.0001\n","decoder_learning_ratio = 5.0\n","n_iteration = 57700\n","print_every = 5770\n","save_every = 10000\n","\n","# Ensure dropout layers are in train mode\n","encoder.train()\n","decoder.train()\n","\n","# Initialize optimizers\n","print('Building optimizers ...')\n","encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n","decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n","if loadFilename:\n","    encoder_optimizer.load_state_dict(encoder_optimizer_sd)\n","    decoder_optimizer.load_state_dict(decoder_optimizer_sd)\n","\n","# If you have CUDA, configure CUDA to call\n","for state in encoder_optimizer.state.values():\n","    for k, v in state.items():\n","        if isinstance(v, torch.Tensor):\n","            state[k] = v.cuda()\n","\n","for state in decoder_optimizer.state.values():\n","    for k, v in state.items():\n","        if isinstance(v, torch.Tensor):\n","            state[k] = v.cuda()\n","\n","# Run training iterations\n","print(\"Starting Training!\")\n","trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,\n","           embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\n","           print_every, save_every, clip, loadFilename)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4895073,"sourceId":8250125,"sourceType":"datasetVersion"}],"dockerImageVersionId":30698,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"}},"nbformat":4,"nbformat_minor":4}
